{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZqsoLCavclt"
      },
      "source": [
        "copyright 2024: *XIN CHANG, Politechnika Warszawska*<br>\n",
        "(notatnik adresowany do student√≥w: ENNCA)\n",
        "$\\newcommand{\\xx}[2]{(#1)(#2)}$\n",
        "$\\newcommand{\\bb}[1]{\\mathbb{#1}}$\n",
        "$\\newcommand{\\cl}[1]{\\mathcal{#1}}$\n",
        "$\\newcommand{\\tp}[1]{{#1}^{\\intercal}}$\n",
        "$\\newcommand{\\tr}[1]{\\text{trace}\\left[#1\\right]}$\n",
        "$\\newcommand{\\inv}[1]{\\in\\bb{R}^{#1}}$\n",
        "$\\newcommand{\\inm}[2]{\\in\\bb{R}^{#1\\times#2}}$\n",
        "$\\newcommand{\\invc}[1]{\\in\\bb{C}^{#1}}$\n",
        "$\\newcommand{\\inmc}[2]{\\in\\bb{C}^{#1\\times#2}}$\n",
        "$\\newcommand{\\rbox}[2]{\\mathrel{\\raise{#1}{#2}}}$\n",
        "$\\newcommand{\\xconv}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{2.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{C}}\\kern{-6.5pt}\\raise{4.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{0pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{2.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xdense}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{F}}\\kern{-4.5pt}\\raise{1.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{2pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xpool}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-3pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{P}}\\kern{-6.5pt}\\raise{0.8pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{0pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xinp}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\cl{I}}\\kern{-4.5pt}\\raise{1.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{2pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xdrop}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{D}}\\kern{-4.5pt}\\raise{1.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{0.5pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xmerge}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{M}}\\kern{-4.5pt}\\raise{1.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{2pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\newcommand{\\xgeneral}[5]{\n",
        "\\begin{array}[]{r}{\\tiny{#4\\ }}\\\\\\raise{1.5pt}{{\\tiny{#3}}}\\end{array}\n",
        "\\kern{-4pt}\n",
        "\\begin{array}[]{l}{\\LARGE\\bb{Q}}\\kern{-9.0pt}\\raise{4.5pt}{{\\tiny{#5}}}\\end{array}\n",
        "\\kern{2pt}\n",
        "\\begin{array}[]{l}{\\tiny {#2}}\\\\\\raise{1.5pt}{{\\tiny{#1}}}\\end{array}}$\n",
        "$\\def\\ds{\\displaystyle}$\n",
        "$\\def\\ass{\\leftarrow}$\n",
        "$\\def\\od#1#2{\\nabla_{#2}#1}$\n",
        "$\\def\\tod#1#2{\\tp{\\nabla}_{#2}{#1}}$\n",
        "$\\def\\cl#1{{\\cal#1}}$\n",
        "$\\def\\sp#1#2{\\frac{\\partial#1}{\\partial#2}}$\n",
        "$\\def\\eqd{\\doteq}$\n",
        "$\\def\\ra{\\rightarrow}$\n",
        "$\\def\\lra{\\longrightarrow}$\n",
        "$\\def\\ovra#1{\\overset{#1}{\\lra}}$\n",
        "$\\def\\dra{\\overset{\\circ}{\\lra}}$\n",
        "$\\def\\xeq#1{\\overset{#1}{=}}$\n",
        "$\\def\\ov#1{\\overline{#1}}$\n",
        "$\\def\\dotp#1#2{\\left\\langle#1,#2\\right\\rangle}$\n",
        "$\\def\\th#1{\\ov{#1}^{\\intercal}}$\n",
        "$\\def\\rv#1{\\widetilde{#1}}$\n",
        "$\\def\\vars#1#2{\\mathtt{var}_{#1}{\\left[#2\\right]}}$\n",
        "$\\def\\pmodd#1{\\kern{-1mm}\\pmod{#1}}$\n",
        "$\\def\\pdt#1#2#3{\\frac{\\partial^2 #1}{\\partial #2\\partial #3}}$\n",
        "$\\def\\diag#1{\\mathtt{diag}\\left[#1\\right]}$\n",
        "$\\def\\rank#1{\\mathtt{rank}\\left[#1\\right]}$\n",
        "$\\def\\tr#1{\\mathtt{tr}\\left[#1\\right]}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDS_C9ZIAiy2"
      },
      "source": [
        "#Pipeline: Prepare float32 models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFTv1oJLZ--"
      },
      "source": [
        "##Prepare the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r_kA_wDD2tkC",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E3kMRO2J2uoj",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Training transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(56),\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomRotation(10),      # Randomly rotate images by up to 10 degrees\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std for each channel\n",
        "])\n",
        "\n",
        "# Validation transformations\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(56),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std for each channel\n",
        "])\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFjpD7FWaB8e",
        "metadata": {},
        "outputId": "56eb4605-1c8f-4472-a949-dd00d216bfb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load and transform the CIFAR-10 training dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,  # Adjusted batch size for GPU memory considerations\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Load and transform the CIFAR-10 validation dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=val_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,  # Adjusted batch size for GPU memory considerations\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9To8QM9Ldop"
      },
      "source": [
        "## Prepare the training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UENDs_UM26Od",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter  # For logging purposes\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler\n",
        "\n",
        "def train(model, trainloader, testloader, criterion, optimizer, total_epochs, scheduler, saving_dir):\n",
        "    writer = SummaryWriter(saving_dir)  # Initializes a writer for logging to TensorBoard\n",
        "\n",
        "    # Checks if a CUDA GPU is available and moves the model to GPU if possible\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    # Starts the training loop\n",
        "    for epoch in range(total_epochs):\n",
        "        model.train()  # Sets the model to training mode\n",
        "        running_loss = 0.0  # Variable to accumulate losses for logging\n",
        "\n",
        "        # Iterates over the training data loader\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data  # Unpacks the data\n",
        "            if torch.cuda.is_available():  # Moves data to GPU if available\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "            optimizer.zero_grad()  # Clears the gradients of all optimized tensors\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()  # Performs backward propagation\n",
        "            optimizer.step()  # Performs a single optimization step\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 50 == 0:  # Logs the training loss every 50 mini-batches\n",
        "                print(f'[Epoch: {epoch + 1}, Batch: {i + 1:5d}], Training Loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validation phase after each epoch\n",
        "        model.eval()  # Sets the model to evaluation mode\n",
        "        scheduler.step()  # Adjusts the learning rate based on the scheduler\n",
        "        val_loss, correct, total = 0.0, 0, 0  # Initializes variables for validation metrics\n",
        "\n",
        "        with torch.no_grad():  # Disables gradient calculation\n",
        "            for data in testloader:\n",
        "                images, labels = data\n",
        "                if torch.cuda.is_available():\n",
        "                    images = images.cuda()\n",
        "                    labels = labels.cuda()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(testloader)  # Calculates average validation loss\n",
        "        accuracy = 100 * correct / total  # Calculates validation accuracy\n",
        "\n",
        "        # Logs validation metrics to TensorBoard\n",
        "        print(f'Epoch: {epoch + 1} Validation Loss: {val_loss:.3f} Accuracy: {accuracy:.2f}%')\n",
        "        writer.add_scalar('training loss', running_loss / len(trainloader), epoch)\n",
        "        writer.add_scalar('validation loss', val_loss, epoch)\n",
        "        writer.add_scalar('accuracy', accuracy, epoch)\n",
        "\n",
        "    writer.close()  # Closes the writer and ends logging\n",
        "    print('Finished Training')  # Indicates the end of training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFHyQ9rVLk74"
      },
      "source": [
        "## Select and modify the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIpPc1K-_M--",
        "metadata": {},
        "outputId": "383cc9d4-c18a-4ca2-a549-10499f6afd31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Modify the classifier\n",
        "model.classifier[1] = nn.Linear(model.last_channel, 10)  # MobileNetV2's last_channel is the input feature size to the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBDRRecKLo9s"
      },
      "source": [
        "## Run float model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IhuDlE3L7zfL",
        "metadata": {},
        "outputId": "92b639c2-1320-4022-b989-acf025ab0fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, Batch:     1], Training Loss: 0.001\n",
            "[Epoch: 1, Batch:    51], Training Loss: 0.048\n",
            "[Epoch: 1, Batch:   101], Training Loss: 0.034\n",
            "[Epoch: 1, Batch:   151], Training Loss: 0.029\n",
            "[Epoch: 1, Batch:   201], Training Loss: 0.026\n",
            "[Epoch: 1, Batch:   251], Training Loss: 0.024\n",
            "[Epoch: 1, Batch:   301], Training Loss: 0.023\n",
            "[Epoch: 1, Batch:   351], Training Loss: 0.021\n",
            "[Epoch: 1, Batch:   401], Training Loss: 0.022\n",
            "[Epoch: 1, Batch:   451], Training Loss: 0.020\n",
            "[Epoch: 1, Batch:   501], Training Loss: 0.019\n",
            "[Epoch: 1, Batch:   551], Training Loss: 0.019\n",
            "[Epoch: 1, Batch:   601], Training Loss: 0.019\n",
            "[Epoch: 1, Batch:   651], Training Loss: 0.017\n",
            "[Epoch: 1, Batch:   701], Training Loss: 0.018\n",
            "[Epoch: 1, Batch:   751], Training Loss: 0.018\n",
            "[Epoch: 1, Batch:   801], Training Loss: 0.017\n",
            "[Epoch: 1, Batch:   851], Training Loss: 0.017\n",
            "[Epoch: 1, Batch:   901], Training Loss: 0.017\n",
            "[Epoch: 1, Batch:   951], Training Loss: 0.016\n",
            "[Epoch: 1, Batch:  1001], Training Loss: 0.017\n",
            "[Epoch: 1, Batch:  1051], Training Loss: 0.018\n",
            "[Epoch: 1, Batch:  1101], Training Loss: 0.016\n",
            "[Epoch: 1, Batch:  1151], Training Loss: 0.015\n",
            "[Epoch: 1, Batch:  1201], Training Loss: 0.016\n",
            "[Epoch: 1, Batch:  1251], Training Loss: 0.016\n",
            "[Epoch: 1, Batch:  1301], Training Loss: 0.015\n",
            "[Epoch: 1, Batch:  1351], Training Loss: 0.016\n",
            "[Epoch: 1, Batch:  1401], Training Loss: 0.015\n",
            "[Epoch: 1, Batch:  1451], Training Loss: 0.015\n",
            "[Epoch: 1, Batch:  1501], Training Loss: 0.015\n",
            "[Epoch: 1, Batch:  1551], Training Loss: 0.015\n",
            "Epoch: 1 Validation Loss: 0.484 Accuracy: 82.75%\n",
            "[Epoch: 2, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 2, Batch:    51], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   101], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   151], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   201], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   251], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   301], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   351], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   401], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   451], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   501], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   551], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   601], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   651], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   701], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   751], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   801], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   851], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:   901], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:   951], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:  1001], Training Loss: 0.014\n",
            "[Epoch: 2, Batch:  1051], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:  1101], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:  1151], Training Loss: 0.011\n",
            "[Epoch: 2, Batch:  1201], Training Loss: 0.013\n",
            "[Epoch: 2, Batch:  1251], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:  1301], Training Loss: 0.011\n",
            "[Epoch: 2, Batch:  1351], Training Loss: 0.011\n",
            "[Epoch: 2, Batch:  1401], Training Loss: 0.012\n",
            "[Epoch: 2, Batch:  1451], Training Loss: 0.011\n",
            "[Epoch: 2, Batch:  1501], Training Loss: 0.011\n",
            "[Epoch: 2, Batch:  1551], Training Loss: 0.012\n",
            "Epoch: 2 Validation Loss: 0.421 Accuracy: 85.04%\n",
            "[Epoch: 3, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 3, Batch:    51], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   101], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   151], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   201], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   251], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   301], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   351], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:   401], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   451], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   501], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   551], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:   601], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   651], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:   701], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   751], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:   801], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   851], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   901], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:   951], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1001], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:  1051], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1101], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1151], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1201], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1251], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:  1301], Training Loss: 0.009\n",
            "[Epoch: 3, Batch:  1351], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1401], Training Loss: 0.009\n",
            "[Epoch: 3, Batch:  1451], Training Loss: 0.010\n",
            "[Epoch: 3, Batch:  1501], Training Loss: 0.011\n",
            "[Epoch: 3, Batch:  1551], Training Loss: 0.010\n",
            "Epoch: 3 Validation Loss: 0.380 Accuracy: 86.58%\n",
            "[Epoch: 4, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 4, Batch:    51], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   101], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   151], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   201], Training Loss: 0.010\n",
            "[Epoch: 4, Batch:   251], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   301], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   351], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   401], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   451], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   501], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   551], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   601], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   651], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   701], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   751], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   801], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   851], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:   901], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:   951], Training Loss: 0.010\n",
            "[Epoch: 4, Batch:  1001], Training Loss: 0.010\n",
            "[Epoch: 4, Batch:  1051], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1101], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:  1151], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:  1201], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1251], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1301], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1351], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:  1401], Training Loss: 0.008\n",
            "[Epoch: 4, Batch:  1451], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1501], Training Loss: 0.009\n",
            "[Epoch: 4, Batch:  1551], Training Loss: 0.008\n",
            "Epoch: 4 Validation Loss: 0.330 Accuracy: 88.47%\n",
            "[Epoch: 5, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 5, Batch:    51], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   101], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   151], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   201], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   251], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   301], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   351], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   401], Training Loss: 0.006\n",
            "[Epoch: 5, Batch:   451], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   501], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   551], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   601], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   651], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   701], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   751], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   801], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   851], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:   901], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:   951], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1001], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:  1051], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1101], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1151], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1201], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:  1251], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1301], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:  1351], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1401], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1451], Training Loss: 0.007\n",
            "[Epoch: 5, Batch:  1501], Training Loss: 0.008\n",
            "[Epoch: 5, Batch:  1551], Training Loss: 0.008\n",
            "Epoch: 5 Validation Loss: 0.320 Accuracy: 88.81%\n",
            "[Epoch: 6, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 6, Batch:    51], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   101], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   151], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   201], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   251], Training Loss: 0.007\n",
            "[Epoch: 6, Batch:   301], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   351], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   401], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   451], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   501], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   551], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   601], Training Loss: 0.007\n",
            "[Epoch: 6, Batch:   651], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   701], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   751], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   801], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:   851], Training Loss: 0.005\n",
            "[Epoch: 6, Batch:   901], Training Loss: 0.007\n",
            "[Epoch: 6, Batch:   951], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1001], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1051], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1101], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1151], Training Loss: 0.007\n",
            "[Epoch: 6, Batch:  1201], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1251], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1301], Training Loss: 0.007\n",
            "[Epoch: 6, Batch:  1351], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1401], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1451], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1501], Training Loss: 0.006\n",
            "[Epoch: 6, Batch:  1551], Training Loss: 0.006\n",
            "Epoch: 6 Validation Loss: 0.307 Accuracy: 89.64%\n",
            "[Epoch: 7, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 7, Batch:    51], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   101], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   151], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   201], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   251], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   301], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   351], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   401], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   451], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   501], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   551], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   601], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   651], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:   701], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   751], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   801], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   851], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   901], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:   951], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1001], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1051], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1101], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1151], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1201], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1251], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1301], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1351], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1401], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1451], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1501], Training Loss: 0.006\n",
            "[Epoch: 7, Batch:  1551], Training Loss: 0.005\n",
            "Epoch: 7 Validation Loss: 0.283 Accuracy: 90.36%\n",
            "[Epoch: 8, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 8, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   301], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   451], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   501], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   601], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   801], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   851], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1051], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:  1101], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1301], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:  1351], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1551], Training Loss: 0.005\n",
            "Epoch: 8 Validation Loss: 0.286 Accuracy: 90.44%\n",
            "[Epoch: 9, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 9, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   101], Training Loss: 0.003\n",
            "[Epoch: 9, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 9 Validation Loss: 0.286 Accuracy: 90.30%\n",
            "[Epoch: 10, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 10, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   251], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   401], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   501], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   551], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   751], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   801], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   901], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1101], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1201], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1301], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:  1351], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1501], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 10 Validation Loss: 0.286 Accuracy: 90.41%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "# Assuming total_epochs is defined as the total number of epochs you plan to train\n",
        "# Training\n",
        "total_epochs = 10\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=total_epochs, eta_min=0)  # Set eta_min according to your requirements\n",
        "\n",
        "train(model, trainloader, testloader, criterion, optimizer, total_epochs, scheduler,'output')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jw20sDHLv58"
      },
      "source": [
        "Don't forget to save the model after the training. You can use your own checkpoint for further quantization procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAtEIi0uLs0Z"
      },
      "source": [
        "# Quantization: Prepare fake-quantized model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tcTmUdEPd-P"
      },
      "source": [
        "##Fuse BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYN-G8LtPc-h",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from torch.ao.quantization import quantize_fx\n",
        "model = quantize_fx.fuse_fx(model.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGB-kmjVvLGs"
      },
      "source": [
        "Check what's changed to the model, you should see the batch normalization disappeared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3cPa9uR6P2UZ",
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GraphModule(\n",
              "  (features): Module(\n",
              "    (0): Module(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (2): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (3): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (4): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (5): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (6): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (7): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (8): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (9): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (10): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (11): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (12): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (13): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (14): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (15): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (16): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (17): Module(\n",
              "      (conv): Module(\n",
              "        (0): Module(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Module(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (18): Module(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Module(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbfnhj78MEwJ"
      },
      "source": [
        "##Prepare fake quantizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2A884GzgLWq",
        "metadata": {},
        "outputId": "0a1801d0-608f-49b2-89cc-1c2d7fbc9cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/alibaba/TinyNeuralNetwork.git\n",
            "  Cloning https://github.com/alibaba/TinyNeuralNetwork.git to /tmp/pip-req-build-jddnmecn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/alibaba/TinyNeuralNetwork.git /tmp/pip-req-build-jddnmecn\n",
            "  Resolved https://github.com/alibaba/TinyNeuralNetwork.git to commit fb56fd944aa80bd48f1ef48970eb07286a64fdad\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (6.0.1)\n",
            "Requirement already satisfied: igraph>=0.9 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (0.11.5)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (0.18.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (1.23.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from igraph>=0.9->TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (1.7.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/agorski/Desktop/projects/ENNCA-agorski/.venv/lib/python3.10/site-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork==0.1.0.20240426110442+fb56fd944aa80bd48f1ef48970eb07286a64fdad) (0.2.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/alibaba/TinyNeuralNetwork.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_62LFDITgs1d",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from tinynn.graph.quantization.quantizer import QATQuantizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y0gijjPrhDa4",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "quantizer = QATQuantizer(\n",
        "        model,\n",
        "        torch.randn(1,3,52,52),\n",
        "        work_dir='quant_output',\n",
        "        config={\n",
        "            'asymmetric': True,\n",
        "            'backend': 'qnnpack',\n",
        "            \"disable_requantization_for_cat\": True,\n",
        "            'per_tensor': True,\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2k5RPUh_hbiD",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "model_with_quantizer = quantizer.quantize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaZN5UvMhkFM",
        "metadata": {},
        "outputId": "48fdb1bf-25ff-4c81-9fba-6cad2ae10c47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn4m7SGSf5DZ",
        "metadata": {},
        "outputId": "bc7df5b0-be82-4048-83ee-e9a68ce07cae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9bX_ACAMKgN"
      },
      "source": [
        "##Post training quantization (PTQ) calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GIrL5BcHgDjq",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def calibration(model, num_iteration, dataloader):\n",
        "  iteration_num = num_iteration\n",
        "  count = 0\n",
        "  for data in dataloader:\n",
        "      images, labels = data\n",
        "      if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "      model(images)\n",
        "      count += 1\n",
        "      if count >= iteration_num:\n",
        "        break\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "efMNJeq_MiCa",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "model_with_quantizer = calibration(model_with_quantizer, 50, testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TmAGuonMIhTE",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def eval_model(model, dataloader, criterion):\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          images, labels = data\n",
        "          if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          val_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  val_loss /= len(dataloader)\n",
        "  accuracy = 100 * correct / total\n",
        "\n",
        "  print(f' Validation Loss: {val_loss:.3f} Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NcXyarMO28zO",
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5616862773895264, max_val=0.6169242262840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0120], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.068000078201294)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0774], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.871500015258789, max_val=8.569950103759766)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=5.999396324157715)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2076187133789062, max_val=0.8854575157165527)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0318], device='cuda:0'), zero_point=tensor([119], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7739412784576416, max_val=4.3448591232299805)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.47159573435783386, max_val=0.6099822521209717)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.994483470916748)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0576], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.343481540679932, max_val=5.392568111419678)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0128], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.274559736251831)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0062], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7455154657363892, max_val=0.7912762761116028)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0218], device='cuda:0'), zero_point=tensor([122], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6503677368164062, max_val=2.8981499671936035)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.35414066910743713, max_val=0.2953259348869324)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0064], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6368736028671265)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0323], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.1147236824035645, max_val=3.963390827178955)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.646695852279663)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0026941299438477, max_val=1.2081609964370728)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0277], device='cuda:0'), zero_point=tensor([123], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.407316207885742, max_val=3.645781993865967)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0023], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2797909677028656, max_val=0.28810739517211914)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2081527709960938)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0365], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.237416744232178, max_val=4.6513261795043945)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0101], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.5839977264404297)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0066], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7114899754524231, max_val=0.8431055545806885)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0239], device='cuda:0'), zero_point=tensor([141], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3745458126068115, max_val=2.7075581550598145)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.17814837396144867, max_val=0.182935893535614)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0050], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2788506746292114)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.786178112030029, max_val=5.692560195922852)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.887100100517273)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8801844120025635, max_val=1.0004775524139404)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0184], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5521438121795654, max_val=2.1509275436401367)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0012], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15607787668704987, max_val=0.1518346220254898)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.150164246559143)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0455], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.800979137420654, max_val=3.783212900161743)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0053], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3516392707824707)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9439841508865356, max_val=0.878093421459198)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0167], device='cuda:0'), zero_point=tensor([142], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.361823320388794, max_val=1.8928624391555786)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1780521422624588, max_val=0.19929595291614532)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0056], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4185055494308472)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0152], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3701624870300293, max_val=1.9396767616271973)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2273690700531006)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6255061626434326, max_val=0.6866407990455627)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0180], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3361213207244873, max_val=2.2500951290130615)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.14019843935966492, max_val=0.1711486130952835)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7912585735321045)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0361], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.415748119354248, max_val=4.600194454193115)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.137906551361084)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.863503634929657, max_val=0.8515356183052063)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0141], device='cuda:0'), zero_point=tensor([134], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8879115581512451, max_val=1.7019152641296387)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12180342525243759, max_val=0.11066221445798874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7120382785797119)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0558], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7244715690612793, max_val=7.120298385620117)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3658267259597778)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8693015575408936, max_val=0.715563178062439)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0093], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1859922409057617, max_val=1.1862192153930664)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.08753839880228043, max_val=0.12656117975711823)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7148738503456116)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.354663848876953, max_val=7.785618782043457)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0131], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.345320224761963)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0065], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8339146375656128, max_val=0.648904025554657)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0173], device='cuda:0'), zero_point=tensor([152], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.622126579284668, max_val=1.7910118103027344)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12709102034568787, max_val=0.12937068939208984)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.003056526184082)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0447], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.693244934082031, max_val=5.18040132522583)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.995315432548523)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0041], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4419810175895691, max_val=0.5284506678581238)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0174], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.436366081237793, max_val=2.0009968280792236)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16616035997867584, max_val=0.17211754620075226)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0049], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2457096576690674)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.3014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-38.42955780029297, max_val=30.623842239379883)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0067], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7171519994735718)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0036], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4644911587238312, max_val=0.4392447769641876)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3154959678649902, max_val=1.3470371961593628)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0020], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16261516511440277, max_val=0.25086256861686707)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0052], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3343167304992676)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0575], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.336155414581299, max_val=5.7462921142578125)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0075], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9097392559051514)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9507177472114563, max_val=1.026660680770874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0133], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7284313440322876, max_val=1.6687607765197754)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15818771719932556, max_val=0.20837926864624023)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0042], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0612388849258423)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0225], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.869854211807251, max_val=2.866837501525879)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0082], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.100376844406128)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.37738361954689026, max_val=0.38987594842910767)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0111], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.42605459690094, max_val=1.4166169166564941)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31618672609329224, max_val=0.23030824959278107)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0040], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.009002685546875)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0687], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.75886344909668, max_val=8.172324180603027)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0069], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7570358514785767)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2801416516304016, max_val=0.3171195387840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8487494587898254, max_val=0.885628879070282)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1701088547706604, max_val=0.17824316024780273)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7815797328948975)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0720], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.178143501281738, max_val=6.917560577392578)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0089], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.281726598739624)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0029], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.33153286576271057, max_val=0.3656158447265625)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0098], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2109209299087524, max_val=1.278356909751892)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0011], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.10884089767932892, max_val=0.13733351230621338)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.6457756161689758)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0717], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.690572261810303, max_val=9.145669937133789)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.1408426761627197)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0044], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5549866557121277, max_val=0.45495086908340454)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0077], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9717778563499451, max_val=0.9933271408081055)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0108], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3759934902191162, max_val=1.363816738128662)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.0)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0005], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.06850871443748474, max_val=0.04065240919589996)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0893], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.170804977416992, max_val=11.602507591247559)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0345], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.378779411315918, max_val=4.410043716430664)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0269], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.6270899772644043, max_val=3.2423434257507324)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0329], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.614387035369873, max_val=3.7627484798431396)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0209], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6664812564849854, max_val=2.6503891944885254)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0224], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8988845348358154, max_val=2.808256149291992)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0232], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.906282901763916, max_val=3.0148441791534424)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0200], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.7592060565948486, max_val=2.335808277130127)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1013741493225098, max_val=2.7367019653320312)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0117], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.442396640777588, max_val=1.5325950384140015)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.12191104888916, max_val=1.8827836513519287)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.apply(torch.quantization.disable_observer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkVUMrU3RDCw",
        "metadata": {},
        "outputId": "02541a31-e936-45c6-e242-3844d51dea8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Validation Loss: 0.357 Accuracy: 88.32%\n"
          ]
        }
      ],
      "source": [
        "eval_model(model_with_quantizer, testloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FjPVNWGMz0w"
      },
      "source": [
        "##Prepare Quantization Awareness Training (QAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0U9SBn0lwvK",
        "metadata": {},
        "outputId": "5bb33bbb-ba82-4414-ba44-d04e3b552d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5616862773895264, max_val=0.6169242262840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0120], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.068000078201294)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0774], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.871500015258789, max_val=8.569950103759766)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=5.999396324157715)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2076187133789062, max_val=0.8854575157165527)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0318], device='cuda:0'), zero_point=tensor([119], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7739412784576416, max_val=4.3448591232299805)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.47159573435783386, max_val=0.6099822521209717)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.994483470916748)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0576], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.343481540679932, max_val=5.392568111419678)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0128], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.274559736251831)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0062], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7455154657363892, max_val=0.7912762761116028)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0218], device='cuda:0'), zero_point=tensor([122], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6503677368164062, max_val=2.8981499671936035)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.35414066910743713, max_val=0.2953259348869324)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0064], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6368736028671265)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0323], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.1147236824035645, max_val=3.963390827178955)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.646695852279663)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0026941299438477, max_val=1.2081609964370728)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0277], device='cuda:0'), zero_point=tensor([123], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.407316207885742, max_val=3.645781993865967)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0023], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2797909677028656, max_val=0.28810739517211914)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2081527709960938)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0365], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.237416744232178, max_val=4.6513261795043945)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0101], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.5839977264404297)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0066], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7114899754524231, max_val=0.8431055545806885)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0239], device='cuda:0'), zero_point=tensor([141], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3745458126068115, max_val=2.7075581550598145)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.17814837396144867, max_val=0.182935893535614)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0050], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2788506746292114)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.786178112030029, max_val=5.692560195922852)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.887100100517273)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8801844120025635, max_val=1.0004775524139404)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0184], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5521438121795654, max_val=2.1509275436401367)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0012], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15607787668704987, max_val=0.1518346220254898)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.150164246559143)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0455], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.800979137420654, max_val=3.783212900161743)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0053], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3516392707824707)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9439841508865356, max_val=0.878093421459198)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0167], device='cuda:0'), zero_point=tensor([142], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.361823320388794, max_val=1.8928624391555786)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1780521422624588, max_val=0.19929595291614532)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0056], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4185055494308472)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0152], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3701624870300293, max_val=1.9396767616271973)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2273690700531006)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6255061626434326, max_val=0.6866407990455627)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0180], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3361213207244873, max_val=2.2500951290130615)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.14019843935966492, max_val=0.1711486130952835)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7912585735321045)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0361], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.415748119354248, max_val=4.600194454193115)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.137906551361084)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.863503634929657, max_val=0.8515356183052063)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0141], device='cuda:0'), zero_point=tensor([134], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8879115581512451, max_val=1.7019152641296387)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12180342525243759, max_val=0.11066221445798874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7120382785797119)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0558], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7244715690612793, max_val=7.120298385620117)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3658267259597778)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8693015575408936, max_val=0.715563178062439)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0093], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1859922409057617, max_val=1.1862192153930664)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.08753839880228043, max_val=0.12656117975711823)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7148738503456116)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.354663848876953, max_val=7.785618782043457)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0131], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.345320224761963)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0065], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8339146375656128, max_val=0.648904025554657)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0173], device='cuda:0'), zero_point=tensor([152], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.622126579284668, max_val=1.7910118103027344)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12709102034568787, max_val=0.12937068939208984)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.003056526184082)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0447], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.693244934082031, max_val=5.18040132522583)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.995315432548523)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0041], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4419810175895691, max_val=0.5284506678581238)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0174], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.436366081237793, max_val=2.0009968280792236)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16616035997867584, max_val=0.17211754620075226)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0049], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2457096576690674)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.3014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-38.42955780029297, max_val=30.623842239379883)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0067], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7171519994735718)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0036], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4644911587238312, max_val=0.4392447769641876)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3154959678649902, max_val=1.3470371961593628)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0020], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16261516511440277, max_val=0.25086256861686707)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0052], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3343167304992676)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0575], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.336155414581299, max_val=5.7462921142578125)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0075], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9097392559051514)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9507177472114563, max_val=1.026660680770874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0133], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7284313440322876, max_val=1.6687607765197754)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15818771719932556, max_val=0.20837926864624023)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0042], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0612388849258423)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0225], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.869854211807251, max_val=2.866837501525879)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0082], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.100376844406128)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.37738361954689026, max_val=0.38987594842910767)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0111], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.42605459690094, max_val=1.4166169166564941)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31618672609329224, max_val=0.23030824959278107)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0040], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.009002685546875)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0687], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.75886344909668, max_val=8.172324180603027)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0069], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7570358514785767)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2801416516304016, max_val=0.3171195387840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8487494587898254, max_val=0.885628879070282)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1701088547706604, max_val=0.17824316024780273)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7815797328948975)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0720], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.178143501281738, max_val=6.917560577392578)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0089], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.281726598739624)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0029], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.33153286576271057, max_val=0.3656158447265625)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0098], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2109209299087524, max_val=1.278356909751892)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0011], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.10884089767932892, max_val=0.13733351230621338)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.6457756161689758)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0717], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.690572261810303, max_val=9.145669937133789)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.1408426761627197)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0044], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5549866557121277, max_val=0.45495086908340454)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0077], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9717778563499451, max_val=0.9933271408081055)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0108], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3759934902191162, max_val=1.363816738128662)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.0)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0005], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.06850871443748474, max_val=0.04065240919589996)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0893], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.170804977416992, max_val=11.602507591247559)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0345], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.378779411315918, max_val=4.410043716430664)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0269], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.6270899772644043, max_val=3.2423434257507324)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0329], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.614387035369873, max_val=3.7627484798431396)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0209], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6664812564849854, max_val=2.6503891944885254)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0224], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8988845348358154, max_val=2.808256149291992)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0232], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.906282901763916, max_val=3.0148441791534424)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0200], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.7592060565948486, max_val=2.335808277130127)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1013741493225098, max_val=2.7367019653320312)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0117], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.442396640777588, max_val=1.5325950384140015)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.12191104888916, max_val=1.8827836513519287)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.apply(torch.quantization.disable_observer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRLBWLzCa4Pb",
        "metadata": {},
        "outputId": "6f263589-286e-4cfd-e11a-ba0a8167f142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 1, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   451], Training Loss: 0.005\n",
            "[Epoch: 1, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   701], Training Loss: 0.003\n",
            "[Epoch: 1, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1301], Training Loss: 0.003\n",
            "[Epoch: 1, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1451], Training Loss: 0.003\n",
            "[Epoch: 1, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 1, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 1 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 2, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 2, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1251], Training Loss: 0.005\n",
            "[Epoch: 2, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 2, Batch:  1501], Training Loss: 0.003\n",
            "[Epoch: 2, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 2 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 3, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 3, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   401], Training Loss: 0.003\n",
            "[Epoch: 3, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:   951], Training Loss: 0.003\n",
            "[Epoch: 3, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1151], Training Loss: 0.003\n",
            "[Epoch: 3, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 3, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 3 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 4, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 4, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   601], Training Loss: 0.003\n",
            "[Epoch: 4, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1451], Training Loss: 0.005\n",
            "[Epoch: 4, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 4, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 4 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 5, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 5, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   151], Training Loss: 0.003\n",
            "[Epoch: 5, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   251], Training Loss: 0.003\n",
            "[Epoch: 5, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   751], Training Loss: 0.005\n",
            "[Epoch: 5, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1151], Training Loss: 0.003\n",
            "[Epoch: 5, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1401], Training Loss: 0.003\n",
            "[Epoch: 5, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 5, Batch:  1501], Training Loss: 0.005\n",
            "[Epoch: 5, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 5 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 6, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 6, Batch:    51], Training Loss: 0.003\n",
            "[Epoch: 6, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1051], Training Loss: 0.003\n",
            "[Epoch: 6, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 6, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 6 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 7, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 7, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1001], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1151], Training Loss: 0.003\n",
            "[Epoch: 7, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1401], Training Loss: 0.003\n",
            "[Epoch: 7, Batch:  1451], Training Loss: 0.005\n",
            "[Epoch: 7, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 7, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 7 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 8, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 8, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:   951], Training Loss: 0.005\n",
            "[Epoch: 8, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1051], Training Loss: 0.003\n",
            "[Epoch: 8, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1151], Training Loss: 0.003\n",
            "[Epoch: 8, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 8, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 8 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 9, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 9, Batch:    51], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   101], Training Loss: 0.003\n",
            "[Epoch: 9, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   201], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   351], Training Loss: 0.003\n",
            "[Epoch: 9, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1101], Training Loss: 0.003\n",
            "[Epoch: 9, Batch:  1151], Training Loss: 0.005\n",
            "[Epoch: 9, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1301], Training Loss: 0.005\n",
            "[Epoch: 9, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1451], Training Loss: 0.003\n",
            "[Epoch: 9, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 9, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 9 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "[Epoch: 10, Batch:     1], Training Loss: 0.000\n",
            "[Epoch: 10, Batch:    51], Training Loss: 0.003\n",
            "[Epoch: 10, Batch:   101], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   151], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   201], Training Loss: 0.005\n",
            "[Epoch: 10, Batch:   251], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   301], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   351], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   401], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   451], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   501], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   551], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   601], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   651], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   701], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   751], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   801], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   851], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   901], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:   951], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1001], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1051], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1101], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1151], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1201], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1251], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1301], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1351], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1401], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1451], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1501], Training Loss: 0.004\n",
            "[Epoch: 10, Batch:  1551], Training Loss: 0.004\n",
            "Epoch: 10 Validation Loss: 0.357 Accuracy: 88.32%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(model_with_quantizer, trainloader, testloader, criterion, optimizer, total_epochs, scheduler,'output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uwxp1YNQ2M1",
        "metadata": {},
        "outputId": "0b712ace-4538-4b09-d342-d437d06f3c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Validation Loss: 0.357 Accuracy: 88.32%\n"
          ]
        }
      ],
      "source": [
        "eval_model(model_with_quantizer, testloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hQqWefyRH3j"
      },
      "source": [
        "##Output analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRgeFQedTLBB",
        "metadata": {},
        "outputId": "332442d7-ea97-43da-c6fc-8ef545d91908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QuantStub(\n",
              "  (activation_post_process): FakeQuantize(\n",
              "    fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "    (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer._modules['fake_quant_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S4-DsAh2TWmX",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "outputs = {}\n",
        "def hook_fn(module, input, output):\n",
        "    outputs[\"my_desired_layer_output\"] = output\n",
        "# The output of `fake_quant_0` is now stored in `outputs[\"my_desired_layer_output\"]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "74WngYLgqqqY",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(testloader))\n",
        "model_with_quantizer._modules['features_0_0'].register_forward_hook(hook_fn)\n",
        "images = images.cuda()\n",
        "model_with_quantizer(images)\n",
        "desired_output = outputs[\"my_desired_layer_output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX7ISkkmTkVH",
        "metadata": {},
        "outputId": "da22dcd9-6766-443a-a1ea-a7b4159236ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 32, 28, 28])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "desired_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lS9N7O9TU5Vw",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_output_channel(X):\n",
        "  X=X.detach().cpu()\n",
        "  C=desired_output.shape[1]\n",
        "  # Create a figure and a set of subplots\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)  # 1 row, 2 columns\n",
        "  ranges = torch.zeros((X.size(1), 2))  # Two columns for min and max\n",
        "  for i in range(X.size(1)):  # Iterate over channels\n",
        "      channel_data = X[:, i, :, :].flatten()  # Flatten the spatial dimensions\n",
        "      ranges[i, 0] = torch.min(channel_data)  # Min value for this channel\n",
        "      ranges[i, 1] = torch.max(channel_data)  # Max value for this channel\n",
        "\n",
        "  # Convert the ranges to a format suitable for box plot\n",
        "  ranges = ranges.numpy()\n",
        "\n",
        "  # Create the box plot\n",
        "  ax1.boxplot(ranges.transpose(), positions=range(1, C+1), showfliers=False)\n",
        "\n",
        "  ax1.set_title('Range of values for each output channel')\n",
        "\n",
        "  ax2.hist(X.flatten().detach().numpy(),bins=100)\n",
        "  # Plot data on the second subplot\n",
        "  ax2.set_title('Distribution')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFHcCycaRYiq"
      },
      "source": [
        "Check the quantized output after first conv layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "aFJm3aDsVG5c",
        "metadata": {},
        "outputId": "db668e9a-43a4-4ded-fd93-0c4186015247"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_output_channel(desired_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRJwPwEyRPPq"
      },
      "source": [
        "Disable the quantization to see the float output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LBQRgRST3ly",
        "metadata": {},
        "outputId": "84f403f8-4c0f-4493-b70a-11b4e29a85c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5616862773895264, max_val=0.6169242262840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0120], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.068000078201294)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0774], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.871500015258789, max_val=8.569950103759766)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=5.999396324157715)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2076187133789062, max_val=0.8854575157165527)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0318], device='cuda:0'), zero_point=tensor([119], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7739412784576416, max_val=4.3448591232299805)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.47159573435783386, max_val=0.6099822521209717)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.994483470916748)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0576], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.343481540679932, max_val=5.392568111419678)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0128], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.274559736251831)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0062], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7455154657363892, max_val=0.7912762761116028)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0218], device='cuda:0'), zero_point=tensor([122], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6503677368164062, max_val=2.8981499671936035)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.35414066910743713, max_val=0.2953259348869324)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0064], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6368736028671265)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0323], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.1147236824035645, max_val=3.963390827178955)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.646695852279663)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0026941299438477, max_val=1.2081609964370728)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0277], device='cuda:0'), zero_point=tensor([123], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.407316207885742, max_val=3.645781993865967)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0023], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2797909677028656, max_val=0.28810739517211914)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2081527709960938)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0365], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.237416744232178, max_val=4.6513261795043945)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0101], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.5839977264404297)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0066], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7114899754524231, max_val=0.8431055545806885)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0239], device='cuda:0'), zero_point=tensor([141], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3745458126068115, max_val=2.7075581550598145)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.17814837396144867, max_val=0.182935893535614)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0050], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2788506746292114)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.786178112030029, max_val=5.692560195922852)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.887100100517273)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8801844120025635, max_val=1.0004775524139404)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0184], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5521438121795654, max_val=2.1509275436401367)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0012], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15607787668704987, max_val=0.1518346220254898)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.150164246559143)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0455], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.800979137420654, max_val=3.783212900161743)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0053], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3516392707824707)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9439841508865356, max_val=0.878093421459198)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0167], device='cuda:0'), zero_point=tensor([142], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.361823320388794, max_val=1.8928624391555786)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1780521422624588, max_val=0.19929595291614532)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0056], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4185055494308472)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0152], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3701624870300293, max_val=1.9396767616271973)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2273690700531006)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6255061626434326, max_val=0.6866407990455627)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0180], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3361213207244873, max_val=2.2500951290130615)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.14019843935966492, max_val=0.1711486130952835)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7912585735321045)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0361], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.415748119354248, max_val=4.600194454193115)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.137906551361084)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.863503634929657, max_val=0.8515356183052063)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0141], device='cuda:0'), zero_point=tensor([134], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8879115581512451, max_val=1.7019152641296387)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12180342525243759, max_val=0.11066221445798874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7120382785797119)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0558], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7244715690612793, max_val=7.120298385620117)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3658267259597778)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8693015575408936, max_val=0.715563178062439)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0093], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1859922409057617, max_val=1.1862192153930664)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.08753839880228043, max_val=0.12656117975711823)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7148738503456116)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.354663848876953, max_val=7.785618782043457)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0131], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.345320224761963)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0065], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8339146375656128, max_val=0.648904025554657)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0173], device='cuda:0'), zero_point=tensor([152], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.622126579284668, max_val=1.7910118103027344)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12709102034568787, max_val=0.12937068939208984)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.003056526184082)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0447], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.693244934082031, max_val=5.18040132522583)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.995315432548523)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0041], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4419810175895691, max_val=0.5284506678581238)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0174], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.436366081237793, max_val=2.0009968280792236)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16616035997867584, max_val=0.17211754620075226)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0049], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2457096576690674)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.3014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-38.42955780029297, max_val=30.623842239379883)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0067], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7171519994735718)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0036], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4644911587238312, max_val=0.4392447769641876)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3154959678649902, max_val=1.3470371961593628)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0020], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16261516511440277, max_val=0.25086256861686707)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0052], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3343167304992676)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0575], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.336155414581299, max_val=5.7462921142578125)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0075], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9097392559051514)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9507177472114563, max_val=1.026660680770874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0133], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7284313440322876, max_val=1.6687607765197754)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15818771719932556, max_val=0.20837926864624023)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0042], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0612388849258423)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0225], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.869854211807251, max_val=2.866837501525879)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0082], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.100376844406128)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.37738361954689026, max_val=0.38987594842910767)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0111], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.42605459690094, max_val=1.4166169166564941)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31618672609329224, max_val=0.23030824959278107)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0040], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.009002685546875)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0687], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.75886344909668, max_val=8.172324180603027)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0069], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7570358514785767)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2801416516304016, max_val=0.3171195387840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8487494587898254, max_val=0.885628879070282)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1701088547706604, max_val=0.17824316024780273)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7815797328948975)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0720], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.178143501281738, max_val=6.917560577392578)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0089], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.281726598739624)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0029], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.33153286576271057, max_val=0.3656158447265625)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0098], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2109209299087524, max_val=1.278356909751892)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0011], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.10884089767932892, max_val=0.13733351230621338)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.6457756161689758)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0717], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.690572261810303, max_val=9.145669937133789)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.1408426761627197)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0044], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5549866557121277, max_val=0.45495086908340454)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0077], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9717778563499451, max_val=0.9933271408081055)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0108], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3759934902191162, max_val=1.363816738128662)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.0)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0005], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.06850871443748474, max_val=0.04065240919589996)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0893], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.170804977416992, max_val=11.602507591247559)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0345], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.378779411315918, max_val=4.410043716430664)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0269], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.6270899772644043, max_val=3.2423434257507324)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0329], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.614387035369873, max_val=3.7627484798431396)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0209], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6664812564849854, max_val=2.6503891944885254)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0224], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8988845348358154, max_val=2.808256149291992)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0232], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.906282901763916, max_val=3.0148441791534424)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0200], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.7592060565948486, max_val=2.335808277130127)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1013741493225098, max_val=2.7367019653320312)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0117], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.442396640777588, max_val=1.5325950384140015)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.12191104888916, max_val=1.8827836513519287)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.apply(torch.quantization.disable_fake_quant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z3vJrf7fT_nf",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "outputs = {}\n",
        "def hook_fn(module, input, output):\n",
        "    outputs[\"my_desired_layer_output\"] = output\n",
        "model_with_quantizer._modules['features_0_0'].register_forward_hook(hook_fn)\n",
        "model_with_quantizer(images)\n",
        "\n",
        "# The output of `fake_quant_0` is now stored in `outputs[\"my_desired_layer_output\"]`\n",
        "desired_output = outputs[\"my_desired_layer_output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "-NZwRO76VgVf",
        "metadata": {},
        "outputId": "56341185-d483-484b-c7ce-fcddfa774800"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_output_channel(desired_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaH2xretaoKJ",
        "metadata": {},
        "outputId": "1958af6b-dc6b-4f39-cff3-65ab4cc19427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QGraphModule(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
              "    )\n",
              "  )\n",
              "  (features_0_0): Conv2d(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5616862773895264, max_val=0.6169242262840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_0): DeQuantStub()\n",
              "  (fake_activ_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0120], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.068000078201294)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_0): Conv2d(\n",
              "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0774], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.871500015258789, max_val=8.569950103759766)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_1): DeQuantStub()\n",
              "  (fake_activ_quant_1): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=5.999396324157715)\n",
              "    )\n",
              "  )\n",
              "  (features_1_conv_1): Conv2d(\n",
              "    32, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2076187133789062, max_val=0.8854575157165527)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0318], device='cuda:0'), zero_point=tensor([119], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7739412784576416, max_val=4.3448591232299805)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_0): Conv2d(\n",
              "    16, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0048], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.47159573435783386, max_val=0.6099822521209717)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_2): DeQuantStub()\n",
              "  (fake_activ_quant_2): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.994483470916748)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_0): Conv2d(\n",
              "    96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0576], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.343481540679932, max_val=5.392568111419678)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_3): DeQuantStub()\n",
              "  (fake_activ_quant_3): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0128], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.274559736251831)\n",
              "    )\n",
              "  )\n",
              "  (features_2_conv_2): Conv2d(\n",
              "    96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0062], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7455154657363892, max_val=0.7912762761116028)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0218], device='cuda:0'), zero_point=tensor([122], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6503677368164062, max_val=2.8981499671936035)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.35414066910743713, max_val=0.2953259348869324)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_4): DeQuantStub()\n",
              "  (fake_activ_quant_4): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0064], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6368736028671265)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0323], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.1147236824035645, max_val=3.963390827178955)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_5): DeQuantStub()\n",
              "  (fake_activ_quant_5): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.646695852279663)\n",
              "    )\n",
              "  )\n",
              "  (features_3_conv_2): Conv2d(\n",
              "    144, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0095], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0026941299438477, max_val=1.2081609964370728)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0277], device='cuda:0'), zero_point=tensor([123], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.407316207885742, max_val=3.645781993865967)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_0): Conv2d(\n",
              "    24, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0023], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2797909677028656, max_val=0.28810739517211914)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_6): DeQuantStub()\n",
              "  (fake_activ_quant_6): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2081527709960938)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_0): Conv2d(\n",
              "    144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0365], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.237416744232178, max_val=4.6513261795043945)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_7): DeQuantStub()\n",
              "  (fake_activ_quant_7): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0101], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.5839977264404297)\n",
              "    )\n",
              "  )\n",
              "  (features_4_conv_2): Conv2d(\n",
              "    144, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0066], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7114899754524231, max_val=0.8431055545806885)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0239], device='cuda:0'), zero_point=tensor([141], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3745458126068115, max_val=2.7075581550598145)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.17814837396144867, max_val=0.182935893535614)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_8): DeQuantStub()\n",
              "  (fake_activ_quant_8): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0050], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2788506746292114)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.786178112030029, max_val=5.692560195922852)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_9): DeQuantStub()\n",
              "  (fake_activ_quant_9): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.887100100517273)\n",
              "    )\n",
              "  )\n",
              "  (features_5_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8801844120025635, max_val=1.0004775524139404)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0184], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5521438121795654, max_val=2.1509275436401367)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0012], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15607787668704987, max_val=0.1518346220254898)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_10): DeQuantStub()\n",
              "  (fake_activ_quant_10): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.150164246559143)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0455], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.800979137420654, max_val=3.783212900161743)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_11): DeQuantStub()\n",
              "  (fake_activ_quant_11): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0053], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3516392707824707)\n",
              "    )\n",
              "  )\n",
              "  (features_6_conv_2): Conv2d(\n",
              "    192, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0074], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9439841508865356, max_val=0.878093421459198)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0167], device='cuda:0'), zero_point=tensor([142], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.361823320388794, max_val=1.8928624391555786)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_0): Conv2d(\n",
              "    32, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1780521422624588, max_val=0.19929595291614532)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_12): DeQuantStub()\n",
              "  (fake_activ_quant_12): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0056], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4185055494308472)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_0): Conv2d(\n",
              "    192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0152], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3701624870300293, max_val=1.9396767616271973)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_13): DeQuantStub()\n",
              "  (fake_activ_quant_13): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0087], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.2273690700531006)\n",
              "    )\n",
              "  )\n",
              "  (features_7_conv_2): Conv2d(\n",
              "    192, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6255061626434326, max_val=0.6866407990455627)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0180], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3361213207244873, max_val=2.2500951290130615)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.14019843935966492, max_val=0.1711486130952835)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_14): DeQuantStub()\n",
              "  (fake_activ_quant_14): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7912585735321045)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0361], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.415748119354248, max_val=4.600194454193115)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_15): DeQuantStub()\n",
              "  (fake_activ_quant_15): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.137906551361084)\n",
              "    )\n",
              "  )\n",
              "  (features_8_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.863503634929657, max_val=0.8515356183052063)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0141], device='cuda:0'), zero_point=tensor([134], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8879115581512451, max_val=1.7019152641296387)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12180342525243759, max_val=0.11066221445798874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_16): DeQuantStub()\n",
              "  (fake_activ_quant_16): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7120382785797119)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0558], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7244715690612793, max_val=7.120298385620117)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_17): DeQuantStub()\n",
              "  (fake_activ_quant_17): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0054], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3658267259597778)\n",
              "    )\n",
              "  )\n",
              "  (features_9_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8693015575408936, max_val=0.715563178062439)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0093], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1859922409057617, max_val=1.1862192153930664)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.08753839880228043, max_val=0.12656117975711823)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_18): DeQuantStub()\n",
              "  (fake_activ_quant_18): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0028], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7148738503456116)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0611], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.354663848876953, max_val=7.785618782043457)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_19): DeQuantStub()\n",
              "  (fake_activ_quant_19): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0131], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.345320224761963)\n",
              "    )\n",
              "  )\n",
              "  (features_10_conv_2): Conv2d(\n",
              "    384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0065], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8339146375656128, max_val=0.648904025554657)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0173], device='cuda:0'), zero_point=tensor([152], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.622126579284668, max_val=1.7910118103027344)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_0): Conv2d(\n",
              "    64, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12709102034568787, max_val=0.12937068939208984)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_20): DeQuantStub()\n",
              "  (fake_activ_quant_20): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.003056526184082)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_0): Conv2d(\n",
              "    384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0447], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.693244934082031, max_val=5.18040132522583)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_21): DeQuantStub()\n",
              "  (fake_activ_quant_21): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.995315432548523)\n",
              "    )\n",
              "  )\n",
              "  (features_11_conv_2): Conv2d(\n",
              "    384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0041], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4419810175895691, max_val=0.5284506678581238)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0174], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.436366081237793, max_val=2.0009968280792236)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0013], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16616035997867584, max_val=0.17211754620075226)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_22): DeQuantStub()\n",
              "  (fake_activ_quant_22): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0049], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2457096576690674)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.3014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-38.42955780029297, max_val=30.623842239379883)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_23): DeQuantStub()\n",
              "  (fake_activ_quant_23): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0067], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7171519994735718)\n",
              "    )\n",
              "  )\n",
              "  (features_12_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0036], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4644911587238312, max_val=0.4392447769641876)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3154959678649902, max_val=1.3470371961593628)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0020], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16261516511440277, max_val=0.25086256861686707)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_24): DeQuantStub()\n",
              "  (fake_activ_quant_24): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0052], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3343167304992676)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0575], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.336155414581299, max_val=5.7462921142578125)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_25): DeQuantStub()\n",
              "  (fake_activ_quant_25): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0075], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9097392559051514)\n",
              "    )\n",
              "  )\n",
              "  (features_13_conv_2): Conv2d(\n",
              "    576, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9507177472114563, max_val=1.026660680770874)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0133], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7284313440322876, max_val=1.6687607765197754)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_0): Conv2d(\n",
              "    96, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0016], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.15818771719932556, max_val=0.20837926864624023)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_26): DeQuantStub()\n",
              "  (fake_activ_quant_26): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0042], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0612388849258423)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_0): Conv2d(\n",
              "    576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0225], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.869854211807251, max_val=2.866837501525879)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_27): DeQuantStub()\n",
              "  (fake_activ_quant_27): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0082], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.100376844406128)\n",
              "    )\n",
              "  )\n",
              "  (features_14_conv_2): Conv2d(\n",
              "    576, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.37738361954689026, max_val=0.38987594842910767)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0111], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.42605459690094, max_val=1.4166169166564941)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31618672609329224, max_val=0.23030824959278107)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_28): DeQuantStub()\n",
              "  (fake_activ_quant_28): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0040], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.009002685546875)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0687], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.75886344909668, max_val=8.172324180603027)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_29): DeQuantStub()\n",
              "  (fake_activ_quant_29): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0069], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7570358514785767)\n",
              "    )\n",
              "  )\n",
              "  (features_15_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2801416516304016, max_val=0.3171195387840271)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0068], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8487494587898254, max_val=0.885628879070282)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0014], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1701088547706604, max_val=0.17824316024780273)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_30): DeQuantStub()\n",
              "  (fake_activ_quant_30): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0031], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.7815797328948975)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0720], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.178143501281738, max_val=6.917560577392578)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_31): DeQuantStub()\n",
              "  (fake_activ_quant_31): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0089], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.281726598739624)\n",
              "    )\n",
              "  )\n",
              "  (features_16_conv_2): Conv2d(\n",
              "    960, 160, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0029], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.33153286576271057, max_val=0.3656158447265625)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0098], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2109209299087524, max_val=1.278356909751892)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_0): Conv2d(\n",
              "    160, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0011], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.10884089767932892, max_val=0.13733351230621338)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_0_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_32): DeQuantStub()\n",
              "  (fake_activ_quant_32): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0025], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.6457756161689758)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_0): Conv2d(\n",
              "    960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0717], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.690572261810303, max_val=9.145669937133789)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_1_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_33): DeQuantStub()\n",
              "  (fake_activ_quant_33): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.1408426761627197)\n",
              "    )\n",
              "  )\n",
              "  (features_17_conv_2): Conv2d(\n",
              "    960, 320, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0044], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5549866557121277, max_val=0.45495086908340454)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0077], device='cuda:0'), zero_point=tensor([126], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9717778563499451, max_val=0.9933271408081055)\n",
              "    )\n",
              "  )\n",
              "  (features_18_0): Conv2d(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0108], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3759934902191162, max_val=1.363816738128662)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (features_18_2): ReLU6(\n",
              "    inplace=True\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (fake_activ_dequant_34): DeQuantStub()\n",
              "  (fake_activ_quant_34): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.0)\n",
              "    )\n",
              "  )\n",
              "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
              "  (classifier_1): Linear(\n",
              "    in_features=1280, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0005], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.06850871443748474, max_val=0.04065240919589996)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0893], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.170804977416992, max_val=11.602507591247559)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0345], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.378779411315918, max_val=4.410043716430664)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0269], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.6270899772644043, max_val=3.2423434257507324)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0329], device='cuda:0'), zero_point=tensor([140], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.614387035369873, max_val=3.7627484798431396)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0209], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6664812564849854, max_val=2.6503891944885254)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0224], device='cuda:0'), zero_point=tensor([130], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8988845348358154, max_val=2.808256149291992)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0232], device='cuda:0'), zero_point=tensor([125], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.906282901763916, max_val=3.0148441791534424)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0200], device='cuda:0'), zero_point=tensor([138], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.7592060565948486, max_val=2.335808277130127)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1013741493225098, max_val=2.7367019653320312)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_8): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0117], device='cuda:0'), zero_point=tensor([124], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.442396640777588, max_val=1.5325950384140015)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_9): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.12191104888916, max_val=1.8827836513519287)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.apply(torch.quantization.enable_fake_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj730FEJ0Gor"
      },
      "source": [
        "# TASK:\n",
        "\n",
        "1.Select another network architecture, for instance, resnet, efficientnet. Perform quantization calibration of per-channel and per-tensor, and then compare their results, check the performance drop after PTQ.\n",
        "(You can select just one, but feel free to test different networks and see how the quantization works)\n",
        "\n",
        "2.Perform QAT training for the per-tensor quantization scheme, and see how much performance you can gain after QAT training.\n",
        "\n",
        "3.Check the output of first conv layer, or any particular layer you want to see for the fake-quantized outputs and float outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Resnet Definition "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "valset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "valloader = torch.utils.data.DataLoader(\n",
        "    valset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Training Loss: 1.6210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Validation Loss: 1.3305, Accuracy: 0.5155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Training Loss: 1.2413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Validation Loss: 1.1784, Accuracy: 0.5756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Training Loss: 1.0249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Validation Loss: 0.9488, Accuracy: 0.6671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Training Loss: 0.8786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Validation Loss: 0.8852, Accuracy: 0.6871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Training Loss: 0.7689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Validation Loss: 0.8231, Accuracy: 0.7129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Training Loss: 0.6814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Validation Loss: 0.7218, Accuracy: 0.7509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Training Loss: 0.6164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Validation Loss: 0.6511, Accuracy: 0.7752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Training Loss: 0.5671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Validation Loss: 0.6522, Accuracy: 0.7809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Training Loss: 0.5251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Validation Loss: 0.6081, Accuracy: 0.7989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Training Loss: 0.4820\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Validation Loss: 0.6849, Accuracy: 0.7761\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\", leave=False)\n",
        "    \n",
        "    for i, (inputs, labels) in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "        progress_bar.update(1)\n",
        "    \n",
        "    epoch_loss /= len(trainloader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {epoch_loss:.4f}\")\n",
        "    \n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    val_loss /= len(valloader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1} Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def calculate_validation_results(model, valloader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            inputs, labels = inputs.to(\"cpu\"), labels.to(\"cpu\")\n",
        "    \n",
        "    val_loss /= len(valloader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6849, Accuracy: 0.7761\n"
          ]
        }
      ],
      "source": [
        "calculate_validation_results(model, valloader)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per channel quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TASK:\n",
        "\n",
        "1.Select another network architecture, for instance, resnet, efficientnet. Perform quantization calibration of per-channel and per-tensor, and then compare their results, check the performance drop after PTQ.\n",
        "(You can select just one, but feel free to test different networks and see how the quantization works)\n",
        "\n",
        "2.Perform QAT training for the per-tensor quantization scheme, and see how much performance you can gain after QAT training.\n",
        "\n",
        "3.Check the output of first conv layer, or any particular layer you want to see for the fake-quantized outputs and float outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1\n",
        "Select another network architecture, for instance, resnet, efficientnet. Perform quantization calibration of per-channel and per-tensor, and then compare their results, check the performance drop after PTQ.\n",
        "(You can select just one, but feel free to test different networks and see how the quantization works)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tinynn.graph.quantization.quantizer import QATQuantizer\n",
        "\n",
        "def calibration(model, num_iteration, dataloader):\n",
        "  for _ in tqdm(range(num_iteration), total=num_iteration):\n",
        "    for data in dataloader:\n",
        "        images, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "        model(images)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per Tensor quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:50<00:00,  4.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6827, Accuracy: 0.7779\n"
          ]
        }
      ],
      "source": [
        "quantizer = QATQuantizer(\n",
        "        model,\n",
        "        torch.randn(1,3,32,32),\n",
        "        work_dir='quant_output',\n",
        "        config={\n",
        "            'asymmetric': True,\n",
        "            'backend': 'qnnpack',\n",
        "            \"disable_requantization_for_cat\": True,\n",
        "            'per_tensor': True,\n",
        "        })\n",
        "\n",
        "model_with_quantizer = quantizer.quantize()\n",
        "model_with_quantizer.eval()\n",
        "model_with_quantizer = calibration(model_with_quantizer, 50, valloader)\n",
        "calculate_validation_results(model_with_quantizer, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Per channel quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:54<00:00,  4.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6797, Accuracy: 0.7783\n"
          ]
        }
      ],
      "source": [
        "quantizer = QATQuantizer(\n",
        "        model,\n",
        "        torch.randn(1,3,32,32),\n",
        "        work_dir='quant_output',\n",
        "        config={\n",
        "            'asymmetric': True,\n",
        "            'backend': 'qnnpack',\n",
        "            \"disable_requantization_for_cat\": True,\n",
        "            'per_tensor': False,\n",
        "        })\n",
        "\n",
        "model_with_quantizer = quantizer.quantize()\n",
        "model_with_quantizer.eval()\n",
        "model_with_quantizer = calibration(model_with_quantizer, 50, valloader)\n",
        "calculate_validation_results(model_with_quantizer, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Observations:\n",
        "- Orginal: Validation Loss: 0.5466, Accuracy: 0.8171\n",
        "- After per tensor quantization: Validation Loss: 0.5436, Accuracy: 0.8173\n",
        "- After per channel quantization: Validation Loss: 0.5455, Accuracy: 0.8168\n",
        "\n",
        "The differences in accuracy on validation dataset is miniscule for both per tensor and per channel quantization with minimally lower cross-validation loss function for both of them. Per tensor quantization leads to slightly higher accuracy and per channel quantization to lightly lower accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2\n",
        "Perform QAT training for the per-tensor quantization scheme, and see how much performance you can gain after QAT training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Training Loss: 1.6052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Validation Loss: 1.3295, Accuracy: 0.5151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Training Loss: 1.2028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Validation Loss: 1.1446, Accuracy: 0.5916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Training Loss: 0.9884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Validation Loss: 0.9588, Accuracy: 0.6602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Training Loss: 0.8478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Validation Loss: 0.8377, Accuracy: 0.7051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Training Loss: 0.7381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Validation Loss: 0.7624, Accuracy: 0.7352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Training Loss: 0.6677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Validation Loss: 0.7457, Accuracy: 0.7507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Training Loss: 0.6054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Validation Loss: 0.6260, Accuracy: 0.7855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Training Loss: 0.5601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Validation Loss: 0.9000, Accuracy: 0.7202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Training Loss: 0.5163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Validation Loss: 0.5878, Accuracy: 0.8015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Training Loss: 0.4842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Validation Loss: 0.5864, Accuracy: 0.8006\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
        "\n",
        "quantizer = QATQuantizer(\n",
        "        model,\n",
        "        torch.randn(1,3,32,32),\n",
        "        work_dir='quant_output',\n",
        "        config={\n",
        "            'asymmetric': True,\n",
        "            'backend': 'qnnpack',\n",
        "            \"disable_requantization_for_cat\": True,\n",
        "            'per_tensor': True,\n",
        "        })\n",
        "\n",
        "model_with_quantizer = quantizer.quantize()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\", leave=False)\n",
        "    \n",
        "    for i, (inputs, labels) in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "        progress_bar.update(1)\n",
        "    \n",
        "    epoch_loss /= len(trainloader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {epoch_loss:.4f}\")\n",
        "    \n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    val_loss /= len(valloader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1} Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "    scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### When comparing to losses and accuracies without the QAT Training I couldnt observe any increase in performance, only a miniscule decrease. Maybe it's caused by a simple format of the data - images belong to 10 classes and have shape of 3,32,32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3\n",
        "Check the output of first conv layer, or any particular layer you want to see for the fake-quantized outputs and float outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, labels = next(iter(valloader))\n",
        "model_with_quantizer._modules['fake_quant_0']\n",
        "outputs = {}\n",
        "def hook_fn(module, input, output):\n",
        "    outputs[\"my_desired_layer_output\"] = output\n",
        "model_with_quantizer._modules['conv1'].register_forward_hook(hook_fn)\n",
        "images = images.cuda()\n",
        "model_with_quantizer(images)\n",
        "desired_output = outputs[\"my_desired_layer_output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_output_channel(X):\n",
        "  X=X.detach().cpu()\n",
        "  C=desired_output.shape[1]\n",
        "  # Create a figure and a set of subplots\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)  # 1 row, 2 columns\n",
        "  ranges = torch.zeros((X.size(1), 2))  # Two columns for min and max\n",
        "  for i in range(X.size(1)):  # Iterate over channels\n",
        "      channel_data = X[:, i, :, :].flatten()  # Flatten the spatial dimensions\n",
        "      ranges[i, 0] = torch.min(channel_data)  # Min value for this channel\n",
        "      ranges[i, 1] = torch.max(channel_data)  # Max value for this channel\n",
        "\n",
        "  # Convert the ranges to a format suitable for box plot\n",
        "  ranges = ranges.numpy()\n",
        "\n",
        "  # Create the box plot\n",
        "  ax1.boxplot(ranges.transpose(), positions=range(1, C+1), showfliers=False)\n",
        "\n",
        "  ax1.set_title('Range of values for each output channel')\n",
        "\n",
        "  ax2.hist(X.flatten().detach().numpy(),bins=100)\n",
        "  # Plot data on the second subplot\n",
        "  ax2.set_title('Distribution')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_output_channel(desired_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QResNet(\n",
              "  (fake_quant_0): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0203], device='cuda:0'), zero_point=tensor([120], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.429065704345703, max_val=2.7537312507629395)\n",
              "    )\n",
              "  )\n",
              "  (conv1): ConvBnReLU2d(\n",
              "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19156514108181, max_val=0.192445307970047)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0276], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=7.048403263092041)\n",
              "    )\n",
              "  )\n",
              "  (bn1): Identity()\n",
              "  (rewritten_relu_0): Identity()\n",
              "  (layer1_0_conv1): ConvBnReLU2d(\n",
              "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.041658371686935425, max_val=0.041663698852062225)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0320], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.155406951904297)\n",
              "    )\n",
              "  )\n",
              "  (layer1_0_bn1): Identity()\n",
              "  (rewritten_relu_1): Identity()\n",
              "  (layer1_0_conv2): ConvBn2d(\n",
              "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.04166456684470177, max_val=0.04166639596223831)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0684], device='cuda:0'), zero_point=tensor([117], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.978658199310303, max_val=9.461211204528809)\n",
              "    )\n",
              "  )\n",
              "  (layer1_0_bn2): Identity()\n",
              "  (layer1_1_conv1): ConvBnReLU2d(\n",
              "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.041665129363536835, max_val=0.041665203869342804)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0355], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=9.0509614944458)\n",
              "    )\n",
              "  )\n",
              "  (layer1_1_bn1): Identity()\n",
              "  (rewritten_relu_2): Identity()\n",
              "  (layer1_1_conv2): ConvBn2d(\n",
              "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.04166550934314728, max_val=0.04166486859321594)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0725], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.27293872833252, max_val=9.219279289245605)\n",
              "    )\n",
              "  )\n",
              "  (layer1_1_bn2): Identity()\n",
              "  (layer2_0_conv1): ConvBnReLU2d(\n",
              "    64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.04166599363088608, max_val=0.041665997356176376)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0340], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.664495468139648)\n",
              "    )\n",
              "  )\n",
              "  (layer2_0_bn1): Identity()\n",
              "  (rewritten_relu_3): Identity()\n",
              "  (layer2_0_conv2): ConvBn2d(\n",
              "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.02946239709854126, max_val=0.029462484642863274)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0695], device='cuda:0'), zero_point=tensor([135], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.357555389404297, max_val=8.36490249633789)\n",
              "    )\n",
              "  )\n",
              "  (layer2_0_bn2): Identity()\n",
              "  (layer2_0_shortcut_0): ConvBn2d(\n",
              "    64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0010], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.12497451901435852, max_val=0.12498423457145691)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0673], device='cuda:0'), zero_point=tensor([139], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.356484413146973, max_val=7.799884796142578)\n",
              "    )\n",
              "  )\n",
              "  (layer2_0_shortcut_1): Identity()\n",
              "  (layer2_1_conv1): ConvBnReLU2d(\n",
              "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.02946261502802372, max_val=0.029461722820997238)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0317], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.072467803955078)\n",
              "    )\n",
              "  )\n",
              "  (layer2_1_bn1): Identity()\n",
              "  (rewritten_relu_4): Identity()\n",
              "  (layer2_1_conv2): ConvBn2d(\n",
              "    128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.029462112113833427, max_val=0.029462464153766632)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0661], device='cuda:0'), zero_point=tensor([134], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.860177040100098, max_val=7.98853874206543)\n",
              "    )\n",
              "  )\n",
              "  (layer2_1_bn2): Identity()\n",
              "  (layer3_0_conv1): ConvBnReLU2d(\n",
              "    128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.029462628066539764, max_val=0.02946220338344574)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0353], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.993168830871582)\n",
              "    )\n",
              "  )\n",
              "  (layer3_0_bn1): Identity()\n",
              "  (rewritten_relu_5): Identity()\n",
              "  (layer3_0_conv2): ConvBn2d(\n",
              "    256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.020833201706409454, max_val=0.020833050832152367)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0682], device='cuda:0'), zero_point=tensor([141], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.61677074432373, max_val=7.7841901779174805)\n",
              "    )\n",
              "  )\n",
              "  (layer3_0_bn2): Identity()\n",
              "  (layer3_0_shortcut_0): ConvBn2d(\n",
              "    128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0007], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.08837002515792847, max_val=0.08838647603988647)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0682], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.677361488342285, max_val=8.707974433898926)\n",
              "    )\n",
              "  )\n",
              "  (layer3_0_shortcut_1): Identity()\n",
              "  (layer3_1_conv1): ConvBnReLU2d(\n",
              "    256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.02083304338157177, max_val=0.020833048969507217)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0319], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.140838623046875)\n",
              "    )\n",
              "  )\n",
              "  (layer3_1_bn1): Identity()\n",
              "  (rewritten_relu_6): Identity()\n",
              "  (layer3_1_conv2): ConvBn2d(\n",
              "    256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.020833149552345276, max_val=0.020833207294344902)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0652], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.283333778381348, max_val=8.34689998626709)\n",
              "    )\n",
              "  )\n",
              "  (layer3_1_bn2): Identity()\n",
              "  (layer4_0_conv1): ConvBnReLU2d(\n",
              "    256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0002], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.020833199843764305, max_val=0.020833207294344902)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0316], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.060914993286133)\n",
              "    )\n",
              "  )\n",
              "  (layer4_0_bn1): Identity()\n",
              "  (rewritten_relu_7): Identity()\n",
              "  (layer4_0_conv2): ConvBn2d(\n",
              "    512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0001], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.014731303788721561, max_val=0.014731314033269882)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0737], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.452037811279297, max_val=9.344226837158203)\n",
              "    )\n",
              "  )\n",
              "  (layer4_0_bn2): Identity()\n",
              "  (layer4_0_shortcut_0): ConvBn2d(\n",
              "    256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0005], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.06249828636646271, max_val=0.06249948590993881)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0650], device='cuda:0'), zero_point=tensor([112], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.2910003662109375, max_val=9.2907133102417)\n",
              "    )\n",
              "  )\n",
              "  (layer4_0_shortcut_1): Identity()\n",
              "  (layer4_1_conv1): ConvBnReLU2d(\n",
              "    512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0001], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.014731287956237793, max_val=0.01473130751401186)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0329], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.400938034057617)\n",
              "    )\n",
              "  )\n",
              "  (layer4_1_bn1): Identity()\n",
              "  (rewritten_relu_8): Identity()\n",
              "  (layer4_1_conv2): ConvBn2d(\n",
              "    512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0001], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.014731314033269882, max_val=0.014731301926076412)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0612], device='cuda:0'), zero_point=tensor([127], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.764464378356934, max_val=7.836841583251953)\n",
              "    )\n",
              "  )\n",
              "  (layer4_1_bn2): Identity()\n",
              "  (linear): Linear(\n",
              "    in_features=512, out_features=10, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0003], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.04418852552771568, max_val=0.044192343950271606)\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0102], device='cuda:0'), zero_point=tensor([167], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.704447865486145, max_val=0.9052394032478333)\n",
              "    )\n",
              "  )\n",
              "  (fake_dequant_0): DeQuantStub()\n",
              "  (float_functional_simple_0): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0499], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=12.718454360961914)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_1): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0598], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=15.246150970458984)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_2): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0539], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=13.738592147827148)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_3): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0657], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=16.741275787353516)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_4): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0476], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=12.14177417755127)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_5): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0626], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=15.955482482910156)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_6): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0501], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=12.768486022949219)\n",
              "    )\n",
              "  )\n",
              "  (float_functional_simple_7): FloatFunctional(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([0], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0633], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
              "      (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=16.138132095336914)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_quantizer.apply(torch.quantization.disable_fake_quant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "outputs = {}\n",
        "def hook_fn(module, input, output):\n",
        "    outputs[\"my_desired_layer_output\"] = output\n",
        "model_with_quantizer._modules['conv1'].register_forward_hook(hook_fn)\n",
        "model_with_quantizer(images)\n",
        "\n",
        "# The output of `fake_quant_0` is now stored in `outputs[\"my_desired_layer_output\"]`\n",
        "desired_output = outputs[\"my_desired_layer_output\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_output_channel(desired_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
